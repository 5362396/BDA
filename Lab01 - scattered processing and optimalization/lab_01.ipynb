{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bee397b-0c28-42ae-8511-97abec931f9e",
   "metadata": {},
   "source": [
    "# lab_01 - Czy na pewno już potrzebujesz narzędzi BIG DATA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24447e9-0522-49c1-98b9-f9697276b73d",
   "metadata": {},
   "source": [
    "# 1. Przetwarzanie rozproszone - wady i zalety.\n",
    "\n",
    "Po narzędzia do przetwarzania dużych zbiorów danych sięgamy zazwyczaj wtedy, kiedy ich przetwarzanie lokalnie staje się niemożliwe lub problematyczne. Zazwyczaj wtedy, gdy ilość przetwarzanych danych nie jest możliwa do \"upchnięcia\" w dostępnej pamięci RAM (lub pamięci kart GPU) i szukamy sposobu na skalowanie architektury poziomo.\n",
    "Jednak czy zrobiliśmy wystarczająco dużo, aby zoptymalizować wykorzystanie tej pamięci? \n",
    "Przetwarzanie rozproszone, które jest sercem przetwarzania danych o wolumenie big data, ma swoje zalety, ale również i wady.\n",
    "\n",
    "**Zalety przetwarzania rozproszonego:**\n",
    "* możliwość rozłożenia pracy na większą ilość węzłów, których sumaryczna wydajność (procesor) oraz ilość pamięci może być wielokrotnie większa niż sprzętu dostępnego lokalnie,\n",
    "* możliwość dość łatwego skalowania klastra w razie potrzeby,\n",
    "* awaria pojedynczego węzła nie musi zakończyć się niepowodzeniem całego procesu przetwarzania danych,\n",
    "\n",
    "**Wady przetwarzania rozproszonego:**\n",
    "* wymaga dostępu do klastra (konfiguracja, dostępy),\n",
    "* przy nieodpowiednio dobranej konfiguracji do wielkości zbioru danych przetwarzanie może zająć więcej czasu niż lokalnie:\n",
    "  * w zależności od tego gdzie znajdują się dane - czas ich przesłania do klastra i propagacji na poszczególne węzły może być długi,\n",
    "  * nieodpowiednie dobranie wielkości partycji (w sensie fragmentów zbioru do przetworzenia) do parametrów klastra może spowodować, że węzły przez większośc czasu będą oczekiwały na zakończenie zadań zależnych zamiast faktycznie coś liczyć. Poprawne dobranie parametrów wymaga doświadczenia, ale czasem wielu prób przed wdrożeniem produkcyjnym.\n",
    "* koszt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6c4c9-fd44-46e8-9fbe-3fc1f1900b2e",
   "metadata": {},
   "source": [
    "# 2. Optymalizacja. Co możemy zrobić?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb0431-73de-4788-8cd2-ea36a23f65ec",
   "metadata": {},
   "source": [
    "## 2.1 Optymalizacja wykorzystania pamięci.\n",
    "\n",
    "Każdy punkt danych, który jest wczytany do pamięci RAM zajmuje jej część w zależności od typu, jaki został mu przydzielony. W zależności od języka programowania oraz wybranej struktury danych te wielkości mogą się bardzo różnić. Przykłady optymalizacji zaprezentowane zostaną w języku Python i z użyciem najpopularniejszych bibliotekach do przetwarzania danych czyli numpy oraz pandas.\n",
    "\n",
    "Proces doboru bardziej optymalnego typu danych można rozszerzyć o zmianę zakresu (dziedziny) tych danych, który nazywa się kwantyzacją (ang. quantization) i jest obecnie powszechnie stosowany m.in. do zmniejszania rozmiarów modeli LLM.\n",
    "\n",
    "Optymalizacja pamięci możliwa jest również na poziomie pamięci dyskowej, gdzie powstały bardziej zoptymalizowane formaty przechowywania danych niż te najbardziej popularne wśród osób pracujących na co dzień w obszarze data science. Są to między innymi formaty:\n",
    "* Parquet,\n",
    "* ORC,\n",
    "* AVRO.\n",
    "\n",
    "Temat formatów danych zostanie omówiony w późniejszym czasie.\n",
    "\n",
    "## 2.2 Multiprocessing lokalnie.\n",
    "\n",
    "Nie które języki programowania natywnie wykorzystują wszystkie dostępne rdzenie i nie musimy się zbyt często martwić, aby jako programista wysokopoziomowy optymalizować samodzielnie ten kod na kod wielowątkowy lub wieloprocesowy. CPython, który jest najbardziej popularną implementacją interpretera języka Python, posiada dość poważne ograniczenie w postaci blokady GIL (czytaj więcej: [tu](https://realpython.com/python-gil/), [tu](https://wiki.python.org/moin/GlobalInterpreterLock) oraz [tu](https://bulldogjob.pl/readme/python-dazy-do-usuniecia-gil-i-zwiekszenia-wspolbieznosci)), która dotyczy wielu popularnych bibliotek.\n",
    "\n",
    "## 2.3 Python - biblioteka Numba.\n",
    "\n",
    "Jest to biblioteka dedykowana do optymalizacji ciężkich obliczeń numerycznych poprzez możliwość kompilacji odpowiednio napisanego kodu w języku Python do kodu maszynowego. Numba współpracuje z biblioteką Dask oraz systememSpark, które zostaną zaprezentowane w późniejszym czasie. Możliwe jest również wykorzystanie bilioteki CUDA w celu wykonywania obliczeń na kartach graficznych firmy NVIDIA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3520a9a-64ce-428f-973f-641597efe036",
   "metadata": {},
   "source": [
    "# 3. Optymalizowanie danych w bibliotece pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3017d5e-6b97-4256-a8a7-f0e3cf5d8367",
   "metadata": {},
   "source": [
    "## 3.1 Rozgrzewka."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88635bef-0768-482f-8291-97f48aa539c2",
   "metadata": {},
   "source": [
    "Pakiety niezbędne do wykonania kodu z bieżącego labu:\n",
    "* pandas\n",
    "* numpy\n",
    "* jupyter-lab\n",
    "* fastparquet\n",
    "* filesplit"
   ]
  },
  {
   "cell_type": "code",
   "id": "352f277c-dda6-4826-9f73-b6b235dbe9ef",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-10-02T12:23:32.741139Z",
     "start_time": "2024-10-02T12:23:32.527833Z"
    }
   },
   "source": [
    "# Optymalizację możemy zacząć już na etapie procesu wczytywania danych do pandas DataFrame.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# wczytywanie danych z pliku \"na raz\" - przy małych plikach optymalne rozwiązanie\n",
    "df = pd.read_csv('zamowienia.csv', header=0, sep=';')\n",
    "display(df.head())\n",
    "# poniższa funkcja zwróci nam między innymi typy danych dla każdej kolumny i SZACUNKOWĄ wielkość pamięci, którą zajmuje\n",
    "# nie jest to jednak wielkość dokładna\n",
    "df.info()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Kraj Sprzedawca Data zamowienia  idZamowienia    Utarg\n",
       "0  Polska   Kowalski      2003-07-16         10248   440.00\n",
       "1  Polska   Sowiński      2003-07-10         10249  1863.40\n",
       "2  Niemcy    Peacock      2003-07-12         10250  1552.60\n",
       "3  Niemcy  Leverling      2003-07-15         10251   654.06\n",
       "4  Niemcy    Peacock      2003-07-11         10252  3597.90"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kraj</th>\n",
       "      <th>Sprzedawca</th>\n",
       "      <th>Data zamowienia</th>\n",
       "      <th>idZamowienia</th>\n",
       "      <th>Utarg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polska</td>\n",
       "      <td>Kowalski</td>\n",
       "      <td>2003-07-16</td>\n",
       "      <td>10248</td>\n",
       "      <td>440.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polska</td>\n",
       "      <td>Sowiński</td>\n",
       "      <td>2003-07-10</td>\n",
       "      <td>10249</td>\n",
       "      <td>1863.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Niemcy</td>\n",
       "      <td>Peacock</td>\n",
       "      <td>2003-07-12</td>\n",
       "      <td>10250</td>\n",
       "      <td>1552.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Niemcy</td>\n",
       "      <td>Leverling</td>\n",
       "      <td>2003-07-15</td>\n",
       "      <td>10251</td>\n",
       "      <td>654.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Niemcy</td>\n",
       "      <td>Peacock</td>\n",
       "      <td>2003-07-11</td>\n",
       "      <td>10252</td>\n",
       "      <td>3597.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 799 entries, 0 to 798\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Kraj             799 non-null    object \n",
      " 1   Sprzedawca       799 non-null    object \n",
      " 2   Data zamowienia  799 non-null    object \n",
      " 3   idZamowienia     799 non-null    int64  \n",
      " 4   Utarg            799 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 31.3+ KB\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "b7437389-f97c-4ea9-94b8-edf30d3aa392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:53:28.566457Z",
     "start_time": "2024-10-02T11:53:28.560597Z"
    }
   },
   "source": [
    "# aby sprawdzić ilość pamięci zajmowaną przez ramkę (lub serię) danych, skorzystamy z funkcji memory_usage\n",
    "df.memory_usage()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index               132\n",
       "Kraj               6392\n",
       "Sprzedawca         6392\n",
       "Data zamowienia    6392\n",
       "idZamowienia       6392\n",
       "Utarg              6392\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "78820552-14a6-4801-a6b7-8c8b5873cb9b",
   "metadata": {},
   "source": [
    "Informacja została podana dla każdej kolumny (również indeksu) wyrażona w bajtach. Zwrócony typ danych? Pandas series. Możemy więc to zsumować."
   ]
  },
  {
   "cell_type": "code",
   "id": "8742e3c0-1427-4601-adb8-fc9115fd8d10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:53:38.128688Z",
     "start_time": "2024-10-02T11:53:38.123704Z"
    }
   },
   "source": [
    "sum(df.memory_usage())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32092"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "d9872af3-052c-4e8c-a692-6016ee6137f0",
   "metadata": {},
   "source": [
    "Ta liczba bajtów odpowiada informacji podanej po wywołaniu `df.info()`, ale domyślna wartość parametru `deep=False` powoduje, że nie są to ponownie informacje dokładne. Sprawdźmy więc ile to jest dokładnie."
   ]
  },
  {
   "cell_type": "code",
   "id": "b97e74ae-7403-4eb5-8f9a-a8cb067c9478",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:53:49.374663Z",
     "start_time": "2024-10-02T11:53:49.369902Z"
    }
   },
   "source": [
    "sum(df.memory_usage(deep=True))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150452"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "1731f695-deb6-41bc-9420-57f3db47b091",
   "metadata": {},
   "source": [
    "Widać teraz, że faktycznie jest to wielkość kilkukrotnie większa.\n",
    "\n",
    "Na potrzeby naszych eksperymentów wykorzystamy funkcję, która będzie nam tłumaczyła bajty na coś bardziej przyjaznego (za: https://stackoverflow.com/questions/1094841/get-a-human-readable-version-of-a-file-size)."
   ]
  },
  {
   "cell_type": "code",
   "id": "ead7dabf-0f48-4262-85d5-adb340fb3543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:23:39.532865Z",
     "start_time": "2024-10-02T12:23:39.528684Z"
    }
   },
   "source": [
    "def sizeof_fmt(num, suffix=\"B\"):\n",
    "    for unit in (\"\", \"Ki\", \"Mi\", \"Gi\", \"Ti\", \"Pi\", \"Ei\", \"Zi\"):\n",
    "        if abs(num) < 1024.0:\n",
    "            return f\"{num:3.1f}{unit}{suffix}\"\n",
    "        num /= 1024.0\n",
    "    return f\"{num:.1f}Yi{suffix}\""
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "8fa13363-45b0-4032-a3b9-19e9a138e9dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:55:26.920026Z",
     "start_time": "2024-10-02T11:55:26.915290Z"
    }
   },
   "source": [
    "sizeof_fmt(sum(df.memory_usage(deep=True)))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'146.9KiB'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "69723cb8-9873-453f-b3c3-3705364c2ae2",
   "metadata": {},
   "source": [
    "## 3.2 Optymalizacja wczytywania plików w bibliotece pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76324387-a1b8-4c59-a0d7-b017800e53aa",
   "metadata": {},
   "source": [
    "Plik źródłowy jest mały, więc trudno będzie miarodajnie zmierzyć różnice pomiędzy różnymi sposobami jego wczytywania. Sztucznie zwielokrotnimy więc dane we wczytanej ramce danych i zapiszemy do nowego pliku."
   ]
  },
  {
   "cell_type": "code",
   "id": "7767462a-20bf-44d1-a197-0695fa1645a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:56:51.074026Z",
     "start_time": "2024-10-02T11:56:45.425272Z"
    }
   },
   "source": [
    "# zwiększamy ramkę 50 000 razy - uwaga z wartością tego parametru w zależności od ilości dostępnej pamięci RAM\n",
    "new_df = pd.concat([df.sample(frac=1) for n in range(50_000)])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "d2db8f0f-ccf9-41b1-8eee-191f5e7cc606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:56:53.285712Z",
     "start_time": "2024-10-02T11:56:53.279330Z"
    }
   },
   "source": [
    "new_df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39950000 entries, 767 to 91\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   Kraj             object \n",
      " 1   Sprzedawca       object \n",
      " 2   Data zamowienia  object \n",
      " 3   idZamowienia     int64  \n",
      " 4   Utarg            float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "943e0b37-22d5-4cd6-8e9e-cca151a2e464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:57:43.556570Z",
     "start_time": "2024-10-02T11:57:33.533640Z"
    }
   },
   "source": [
    "sizeof_fmt(sum(new_df.memory_usage(deep=True)))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.3GiB'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "54fe7142-2fba-4f46-a171-ea4a109b6352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:59:27.486144Z",
     "start_time": "2024-10-02T11:58:41.315648Z"
    }
   },
   "source": "new_df.to_csv('data/zamowienia_expanded.csv', header=True, index=False)",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "b7e5313e-bb57-4256-841c-30edd659d9ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:59:56.274698Z",
     "start_time": "2024-10-02T11:59:44.312023Z"
    }
   },
   "source": [
    "start = datetime.now()\n",
    "new_df = pd.read_csv('data/zamowienia_expanded.csv', header=0)\n",
    "print(f\"Czas wczytywania case 1: {datetime.now() - start} sekund\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wczytywania case 1: 0:00:11.957968 sekund\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "37e02ecc-7b08-4b8a-93b1-29882eb5d0b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:23:21.054782Z",
     "start_time": "2024-10-02T12:23:21.051155Z"
    }
   },
   "source": [
    "# aby nie dodawać każdorazowo linii kodu z pomiarem czasu opakujemy tę część w dekorator, który można wielokrotnie reużywać\n",
    "\n",
    "def count_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = datetime.now()\n",
    "        func(*args, **kwargs)\n",
    "        print(f\"Czas wczytywania {func.__name__}: {datetime.now() - start} sekund\")\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "a7f22e78-ce54-4aab-b646-31098015e89e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:23:22.932076Z",
     "start_time": "2024-10-02T12:23:22.928803Z"
    }
   },
   "source": [
    "# Dekoratorów można używać w postaci adnotacji poprzedzającej definicję funkcji, którą następnie musimy jeszcze wywołać.\n",
    "# Poniższe dwie funkcje wczytują plik csv na dwa sposoby, pierwsza wczytuje plik \"na raz\", a druga dzieląc go na części\n",
    "# składające się z ilości linii przekazanych przez parametr chunksize. Każdy wczytany fragment to oddzielna ramka danych,\n",
    "# którą możemy scalić lub przetwarzać oddzielnie.\n",
    "\n",
    "@count_time\n",
    "def read_file_1():\n",
    "    return pd.read_csv('data/zamowienia_expanded.csv', header=0)\n",
    "    \n",
    "@count_time\n",
    "def read_file_2():\n",
    "    chunks = pd.read_csv('data/zamowienia_expanded.csv', header=0, chunksize=4_000_000)\n",
    "    return pd.concat(chunks)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "492c3326-95fd-4fc6-b888-5656cd9c8dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:24:36.931790Z",
     "start_time": "2024-10-02T12:23:47.783468Z"
    }
   },
   "source": [
    "df1 = read_file_1()\n",
    "df2 = read_file_2()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wczytywania read_file_1: 0:00:12.174916 sekund\n",
      "Czas wczytywania read_file_2: 0:00:12.374601 sekund\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "8e70e9ca-ced9-48d4-b340-82359450f641",
   "metadata": {},
   "source": [
    "> Porównując jedynie czas wykonania, niewielką przewagę będzie posiadała metoda wczytująca plik \"na raz\", jednak jeżeli popatrzymy na utylizację pamięci RAM w trakcie obu procesów to w zależności od systemu operacyjnego jej wykorzystanie może się różnić. W systemie Windows przy wykorzystaniu metody wczytującej plik we fragmentach można dostrzec spadki wykorzystania pamięci RAM w dość równych odstępach czasu. Będzie się to zbiegało z wczytywaniem kolejnych chunków. To powoduje, że maksymalny peak utylizacji pamięci RAM będzie niższy w przypadku wczytywania z podziałem na części. Im większy plik, tym ta różnica będzie wzrastać."
   ]
  },
  {
   "cell_type": "code",
   "id": "3455bbdc-0130-47fe-96ad-483cc20669f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:04:00.817651Z",
     "start_time": "2024-10-02T12:03:37.624962Z"
    }
   },
   "source": [
    "sizeof_fmt(sum(df1.memory_usage(deep=True))), sizeof_fmt(sum(df2.memory_usage(deep=True)))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('7.0GiB', '7.0GiB')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "3f0a46f2-8acf-4d8e-a4c7-fedae9f9bb34",
   "metadata": {},
   "source": [
    "Warto też zwrócić uwagę na różnicę w rozmiarze pliku csv vs. rozmiar w pamięci RAM po wczytaniu do pandas DataFrame z domyślnymi typami danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff46152a-a5d2-4860-940f-f064f0f5b075",
   "metadata": {},
   "source": [
    "**Inne formaty plików**"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7a32600-198f-42ed-ba14-19590cb62c40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:07:44.908214Z",
     "start_time": "2024-10-02T12:07:34.024744Z"
    }
   },
   "source": [
    "# format parquet\n",
    "import fastparquet\n",
    "\n",
    "df1.to_parquet('data/zamowienia_expanded.parquet', engine='fastparquet')"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "24b199dd-4fa1-45fb-b5c2-0df8865d4941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:07:49.803344Z",
     "start_time": "2024-10-02T12:07:49.799750Z"
    }
   },
   "source": [
    "@count_time\n",
    "def read_parquet_1():\n",
    "    df = pd.read_parquet('data/zamowienia_expanded.parquet', engine='fastparquet')\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "f449d0bb-7721-4aac-9247-21d4d1113279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:08:04.620126Z",
     "start_time": "2024-10-02T12:07:53.051174Z"
    }
   },
   "source": [
    "df3 = read_parquet_1()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wczytywania read_parquet_1: 0:00:06.564613 sekund\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "6943724d-0e92-4745-9f52-3a0d02eadd42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:08:49.543671Z",
     "start_time": "2024-10-02T12:08:39.647189Z"
    }
   },
   "source": [
    "sizeof_fmt(sum(df3.memory_usage(deep=True)))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.0GiB'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "ad872fb8-1dfe-4f7b-805f-a12d05a8a396",
   "metadata": {},
   "source": [
    "**Multiprocessing**\n",
    "\n",
    "Ten kod należy uruchomić poza Jupyter Notebookiem, gdyż nie jest on obsługiwany dla tego przypadku. Pamiętaj o dodaniu zdefiniowanej wcześniej funkcji `count_time`."
   ]
  },
  {
   "cell_type": "code",
   "id": "32b6e4e7-1323-439f-bf55-9fd2cc69e51e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-02T12:18:44.626102Z"
    }
   },
   "source": [
    "from itertools import repeat\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from filesplit.split import Split\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "def apply_args_and_kwargs(func, args, kwargs):\n",
    "    return func(*args, **kwargs)\n",
    "\n",
    "\n",
    "def starmap_with_kwargs(pool, func, args_iter, kwargs_iter):\n",
    "    args_for_starmap = zip(repeat(func), args_iter, kwargs_iter)\n",
    "    return pool.starmap(apply_args_and_kwargs, args_for_starmap)\n",
    "\n",
    "\n",
    "def split_file(filepath, chunksize, destination):\n",
    "    split = Split(filepath, destination)\n",
    "    split.bylinecount(linecount=chunksize, includeheader=True)\n",
    "\n",
    "\n",
    "@count_time\n",
    "def load_files(directory):\n",
    "\n",
    "    files = [[f\"{directory}/{f}\"] for f in os.listdir(directory) if f.endswith(\".csv\")]\n",
    "\n",
    "    kwargs_list = [\n",
    "        {\n",
    "            'on_bad_lines': \"skip\",\n",
    "        }\n",
    "        for n in range(len(files))\n",
    "    ]\n",
    "\n",
    "    pool = Pool(processes=5)\n",
    "    args_iter = files\n",
    "\n",
    "    results = starmap_with_kwargs(pool, pd.read_csv, args_iter, kwargs_list)\n",
    "    results = pd.concat(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    split_file('data/zamowienia_expanded.csv', 8_000_000, 'data')\n",
    "    df4 = load_files('data')\n",
    "    df4.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cfb79910-3af9-4dd3-bf1a-dc2c6c249b39",
   "metadata": {},
   "source": [
    "## 3.3 Optymalizacja wykorzystania pamięci RAM ramek biblioteki pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c6c4de-dc64-46ab-ac00-fab867774b00",
   "metadata": {},
   "source": [
    "Każda kolumna danych z pliku wczytanego do ramki pandas otrzymuje swój typ, który wynika z zawartości danych w tej kolumnie. Przydzielanie tych typów może być automatyczne (domyślnie), ale można również wskazać pożądany typ lub zmienić go już po wczytaniu danych. Automatyczne przydzielanie typów bywa czasami bardzo nieoptymalne pod kątem wykorzystania pamięci RAM i może w pewnych przypadkach uniemożliwić przetwarzanie zbioru (błędy out of memory), który po optymalizacji tych typów, może na danej maszynie jednak być przetworzony."
   ]
  },
  {
   "cell_type": "code",
   "id": "3db2285e-7bc7-4bed-a63b-2f0325a02e06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:24:36.938731Z",
     "start_time": "2024-10-02T12:24:36.932838Z"
    }
   },
   "source": [
    "# dla przypomnienia zerknijmy na typy danych ustawione automatycznie\n",
    "df1.info() # lub df1.dtypes"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39950000 entries, 0 to 39949999\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   Kraj             object \n",
      " 1   Sprzedawca       object \n",
      " 2   Data zamowienia  object \n",
      " 3   idZamowienia     int64  \n",
      " 4   Utarg            float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "36c958fa-4153-4790-8796-30d0e78d698d",
   "metadata": {},
   "source": [
    "Mamy 3 kolumny typu 'object' (typ str) oraz po jednej typu int64 oraz float64. Pamiętajmy tutaj, że biblioteka pandas wykorzystuje struktury danych z biblioteki numpy (która jest wrapperem do stosownego kodu napisanego w języku C) do przechowywania danych. Mamy więc do dyspozycji znacznie więcej typów niż natywnie dostępne standardowo w Pythonie. Więcej tutaj: https://numpy.org/doc/stable/user/basics.types.html"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8f6b326-58b4-4cf7-a8dc-eec8b8412e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:25:04.378140Z",
     "start_time": "2024-10-02T12:25:02.401338Z"
    }
   },
   "source": [
    "# poznanie zakresu danych powinno pomóc w ocenie czy dobrany typ danych numerycznych jest optymalny\n",
    "df1.describe()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       idZamowienia         Utarg\n",
       "count  3.995000e+07  3.995000e+07\n",
       "mean   1.064718e+04  1.537331e+03\n",
       "std    2.309473e+02  1.859426e+03\n",
       "min    1.024800e+04  1.250000e+01\n",
       "25%    1.044700e+04  4.657000e+02\n",
       "50%    1.064700e+04  9.566700e+02\n",
       "75%    1.084700e+04  1.892250e+03\n",
       "max    1.105700e+04  1.638750e+04"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idZamowienia</th>\n",
       "      <th>Utarg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.995000e+07</td>\n",
       "      <td>3.995000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.064718e+04</td>\n",
       "      <td>1.537331e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.309473e+02</td>\n",
       "      <td>1.859426e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.024800e+04</td>\n",
       "      <td>1.250000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.044700e+04</td>\n",
       "      <td>4.657000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.064700e+04</td>\n",
       "      <td>9.566700e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.084700e+04</td>\n",
       "      <td>1.892250e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.105700e+04</td>\n",
       "      <td>1.638750e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "0c4a9955-46fd-4634-9225-a553fc80eb22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:25:26.384904Z",
     "start_time": "2024-10-02T12:25:24.505943Z"
    }
   },
   "source": [
    "# zmiana domyślnej precyzji formatu wyświetlania danych\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "df1.describe()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        idZamowienia          Utarg\n",
       "count 39950000.00000 39950000.00000\n",
       "mean     10647.17522     1537.33091\n",
       "std        230.94726     1859.42609\n",
       "min      10248.00000       12.50000\n",
       "25%      10447.00000      465.70000\n",
       "50%      10647.00000      956.67000\n",
       "75%      10847.00000     1892.25000\n",
       "max      11057.00000    16387.50000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idZamowienia</th>\n",
       "      <th>Utarg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39950000.00000</td>\n",
       "      <td>39950000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10647.17522</td>\n",
       "      <td>1537.33091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>230.94726</td>\n",
       "      <td>1859.42609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10248.00000</td>\n",
       "      <td>12.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10447.00000</td>\n",
       "      <td>465.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10647.00000</td>\n",
       "      <td>956.67000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10847.00000</td>\n",
       "      <td>1892.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11057.00000</td>\n",
       "      <td>16387.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "60609e22-5aa7-4dca-a40c-fedc76de4cea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:25:40.051194Z",
     "start_time": "2024-10-02T12:25:30.368270Z"
    }
   },
   "source": [
    "for column in df1.columns:\n",
    "    print(f'{column}: {sizeof_fmt(df1[column].memory_usage(deep=True))}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kraj: 2.0GiB\n",
      "Sprzedawca: 2.2GiB\n",
      "Data zamowienia: 2.2GiB\n",
      "idZamowienia: 304.8MiB\n",
      "Utarg: 304.8MiB\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "1aa5d9b6-f0bf-4fe6-b372-022a2331f982",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:25:43.937910Z",
     "start_time": "2024-10-02T12:25:43.901469Z"
    }
   },
   "source": [
    "sizeof_fmt(df1['idZamowienia'].astype(np.int16).memory_usage(deep=True))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'76.2MiB'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "61ac0466-af9d-45a2-9337-66cf0e26b1c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:25:46.411359Z",
     "start_time": "2024-10-02T12:25:45.281972Z"
    }
   },
   "source": [
    "sizeof_fmt(df1['Kraj'].astype('category').memory_usage(deep=True))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38.1MiB'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "9839b62f-0e92-455f-93ff-37fff2e7ed0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:25:48.968469Z",
     "start_time": "2024-10-02T12:25:47.610510Z"
    }
   },
   "source": [
    "sizeof_fmt(df1['Sprzedawca'].astype('category').memory_usage(deep=True))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38.1MiB'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "9cc7286b-2f19-4cf1-94db-958d377138a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:25:52.825098Z",
     "start_time": "2024-10-02T12:25:50.433505Z"
    }
   },
   "source": [
    "sizeof_fmt(pd.to_datetime(df1['Data zamowienia']).memory_usage(deep=True))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'304.8MiB'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "6fe33d37-5017-41ba-9a9c-0cf683ae6eae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:25:56.064577Z",
     "start_time": "2024-10-02T12:25:55.910203Z"
    }
   },
   "source": [
    "# tworzymy pustą ramkę danych, aby przechować w niej dane w nowym, bardziej optymalnym formacie\n",
    "df2 = pd.DataFrame()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "0b5e8df7-9e3e-4d01-8da8-82c74f9bdc89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:26:08.329852Z",
     "start_time": "2024-10-02T12:26:03.240392Z"
    }
   },
   "source": [
    "# zmieniamy format niektórych kolumn\n",
    "df2['Kraj'] = df1['Kraj'].astype('category')\n",
    "df2['Sprzedawca'] = df1['Sprzedawca'].astype('category')\n",
    "df2['Data zamowienia'] = pd.to_datetime(df1['Data zamowienia'])\n",
    "df2['idZamowienia'] = df1['idZamowienia'].astype(np.int16)\n",
    "df2['Utarg'] = df1['Utarg']"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "baee9402-0c0a-47c0-81d3-136853cd9c6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:26:11.891629Z",
     "start_time": "2024-10-02T12:26:11.886968Z"
    }
   },
   "source": [
    "sizeof_fmt(sum(df2.memory_usage(deep=True)))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'762.0MiB'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "8889a2f2-62e9-4ec4-901a-fb8a5ac52e9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:26:23.292548Z",
     "start_time": "2024-10-02T12:26:22.736471Z"
    }
   },
   "source": [
    "# możemy również spróbować wykonać downcasting dla kolumn numerycznych wykorzystując wbudowaną funkcję biblioteki panda to_numeric\n",
    "utarg_downcast = pd.to_numeric(df2[\"Utarg\"], downcast='float')\n",
    "sizeof_fmt(utarg_downcast.memory_usage(deep=True)), utarg_downcast.dtype"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('152.4MiB', dtype('float32'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "1dfa63a4-5321-44d3-bb82-c6bf24e4e39c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:26:27.505905Z",
     "start_time": "2024-10-02T12:26:26.921378Z"
    }
   },
   "source": [
    "# ostatecznie uzyskamy\n",
    "df2['Utarg'] =  pd.to_numeric(df1[\"Utarg\"], downcast='float')\n",
    "sizeof_fmt(sum(df2.memory_usage(deep=True)))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'609.6MiB'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "03db0c54-f8ad-4a50-907c-11efed43e8ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:26:29.672237Z",
     "start_time": "2024-10-02T12:26:29.667229Z"
    }
   },
   "source": [
    "# i dla każdej kolumny oddzielnie\n",
    "for column in df2.columns:\n",
    "    print(f'{column}: {sizeof_fmt(df2[column].memory_usage(deep=True))}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kraj: 38.1MiB\n",
      "Sprzedawca: 38.1MiB\n",
      "Data zamowienia: 304.8MiB\n",
      "idZamowienia: 76.2MiB\n",
      "Utarg: 152.4MiB\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "71457228-cafd-4f38-a5ab-a49f014972a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:26:31.550643Z",
     "start_time": "2024-10-02T12:26:31.544113Z"
    }
   },
   "source": [
    "df2.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39950000 entries, 0 to 39949999\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   Kraj             category      \n",
      " 1   Sprzedawca       category      \n",
      " 2   Data zamowienia  datetime64[ns]\n",
      " 3   idZamowienia     int16         \n",
      " 4   Utarg            float32       \n",
      "dtypes: category(2), datetime64[ns](1), float32(1), int16(1)\n",
      "memory usage: 609.6 MB\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "d6ebde97-bc53-4322-8dde-bd1802d5a6be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:26:36.257845Z",
     "start_time": "2024-10-02T12:26:33.798059Z"
    }
   },
   "source": [
    "df2.describe()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     Data zamowienia   idZamowienia          Utarg\n",
       "count                       39950000 39950000.00000 39950000.00000\n",
       "mean   2004-08-05 22:13:40.025028864    10647.17522     1537.33179\n",
       "min              2003-07-10 00:00:00    10248.00000       12.50000\n",
       "25%              2004-02-26 00:00:00    10447.00000      465.70001\n",
       "50%              2004-09-03 00:00:00    10647.00000      956.66998\n",
       "75%              2005-02-02 00:00:00    10847.00000     1892.25000\n",
       "max              2005-05-01 00:00:00    11057.00000    16387.50000\n",
       "std                              NaN      230.94726     1859.42603"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data zamowienia</th>\n",
       "      <th>idZamowienia</th>\n",
       "      <th>Utarg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39950000</td>\n",
       "      <td>39950000.00000</td>\n",
       "      <td>39950000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2004-08-05 22:13:40.025028864</td>\n",
       "      <td>10647.17522</td>\n",
       "      <td>1537.33179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2003-07-10 00:00:00</td>\n",
       "      <td>10248.00000</td>\n",
       "      <td>12.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2004-02-26 00:00:00</td>\n",
       "      <td>10447.00000</td>\n",
       "      <td>465.70001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2004-09-03 00:00:00</td>\n",
       "      <td>10647.00000</td>\n",
       "      <td>956.66998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2005-02-02 00:00:00</td>\n",
       "      <td>10847.00000</td>\n",
       "      <td>1892.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2005-05-01 00:00:00</td>\n",
       "      <td>11057.00000</td>\n",
       "      <td>16387.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>230.94726</td>\n",
       "      <td>1859.42603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "b487ed57-aae2-4486-bf2e-37d25c87d720",
   "metadata": {},
   "source": [
    "#### Porównanie czasów wykonania dla oryginalnej ramki oraz ramki zoptymalizowanej "
   ]
  },
  {
   "cell_type": "code",
   "id": "77424a71-f3e7-49a6-b57d-3b0b51504c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:26:50.004472Z",
     "start_time": "2024-10-02T12:26:49.830938Z"
    }
   },
   "source": [
    "start = datetime.now()\n",
    "display(df2.groupby(['Sprzedawca']).agg({'Utarg': ['mean']}))\n",
    "print(f'Czas: {datetime.now() - start}')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arek\\AppData\\Local\\Temp\\ipykernel_8428\\392143183.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  display(df2.groupby(['Sprzedawca']).agg({'Utarg': ['mean']}))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                Utarg\n",
       "                 mean\n",
       "Sprzedawca           \n",
       "Callahan   1242.75427\n",
       "Davolio    1559.82983\n",
       "Dudek      1830.43994\n",
       "Fuller     1766.34546\n",
       "King       1745.71631\n",
       "Kowalski   1637.91064\n",
       "Leverling  1609.57019\n",
       "Peacock    1495.12366\n",
       "Sowiński   1115.80969"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Utarg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sprzedawca</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Callahan</th>\n",
       "      <td>1242.75427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Davolio</th>\n",
       "      <td>1559.82983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dudek</th>\n",
       "      <td>1830.43994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuller</th>\n",
       "      <td>1766.34546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>King</th>\n",
       "      <td>1745.71631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kowalski</th>\n",
       "      <td>1637.91064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leverling</th>\n",
       "      <td>1609.57019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peacock</th>\n",
       "      <td>1495.12366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sowiński</th>\n",
       "      <td>1115.80969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas: 0:00:00.169506\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "15a80878-6752-4c03-86cc-408ea4f96f0c",
   "metadata": {},
   "source": [
    "## Zadania\n",
    "\n",
    "> Zbiór danych do wykonania zadań: https://huggingface.co/datasets/vargr/private_instagram/tree/refs%2Fconvert%2Fparquet/default/train\n",
    ">\n",
    "> **UWAGA!**  \n",
    "> W zależności od ilości pamięci RAM pobierz tyle plików, aby możliwe było wczytanie danych do pamięci RAM.\n",
    "> Spróbuj dobrać tyle danych, aby maksymalnie wykorzystać pamięć operacyjną.\n",
    "> Możesz również spróbować dobrać więcej danych niż zmieści się w pamięci operacyjnej w celu wywołania błędu biblioteki pandas \n",
    "\n",
    "**Zadanie 1**  \n",
    "Wczytaj pliki danych i scal je w jedną ramkę DataFrame.\n",
    "Wykonaj analizę typów danych podobnie jak w przykładach.\n",
    "Zmierz wielkość pamięci RAM ramki z domyślnymi typami danych.\n",
    "\n",
    "**Zadanie 2**  \n",
    "Dobierz bardziej optymalne typy danych i ponownie zmierz wielkość zajmowanej pamięci RAM.\n",
    "Porównaj obie wielkości na wykresie (wybierz pasujący typ wykresu).\n",
    "\n",
    "**Zadanie 3**  \n",
    "Wykonaj 3 wybrane operacje (grupowanie + agregacja, filtrowanie, itp.) na całej ramce i zmierz czas wykonania na danych oryginalnych i zoptymalizowanych.\n",
    "Wyświetl te czasy.\n",
    "\n",
    "**Zadanie 4**  \n",
    "Zapisz ramkę jako plik csv, z nagłówkami kolumn, bez indeksu.\n",
    "Sprawdź jaka jest różnica w wielkości pliku csv i sumy wielkości plików w formacie parquet (w eksploratorze, nie trzeba tego robić z poziomu kodu).\n",
    "\n",
    "**Zadanie 5**  \n",
    "Zmierz czas wczytywania danych z pliku csv dla 3 przypadków:\n",
    "* cały plik na raz,\n",
    "* cały plik ze wskazaniem parametru `chunksize` (możesz poeksperymentować z wielkością tego parametru),\n",
    "* z użyciem multiprocessingu zaprezentowanego w przykładzie (wcześniej podziel plik na kilka mniejszych), wskazując ilość procesów jako `ilość_rdzeni - 2` oraz drugi przypadek `(ilosc_rdzeni - 2) * 2`.\n",
    "\n",
    "\n",
    "**Zadanie 6** (z gwiazdką, nie jest obowiązkowe, ale pouczające)  \n",
    "\n",
    "Wczytaj każdy plik podzielony w zadaniu 5 do oddzielnej ramki danych. \n",
    "Dla każdej ramki policz sumę na kolumnie `likes`, a następnie policz sumę tych sum. Tę część zadania wykonaj sekwencyjnie.\n",
    "Teraz wykorzystując multiprocessing (i przykłady z labu) wykonaj to samo zadanie zrównoleglając je. Zmierz czas obu przypadków i go wyświetl.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
